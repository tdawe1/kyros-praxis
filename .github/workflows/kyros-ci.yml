name: kyros-ci
on:
  pull_request:
  push:
    branches: [ main ]
  workflow_dispatch:
jobs:
  build-test:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - name: Set up Node
        uses: actions/setup-node@v4
        with:
          node-version: '20'
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
      - name: Install backend dependencies
        run: |
          cd services/orchestrator
          pip install -r requirements.txt
      - name: Lint backend
        run: |
          cd services/orchestrator
          ruff check .
      - name: Test backend
        run: |
          cd services/orchestrator
          pytest
      - name: Install frontend dependencies
        run: |
          cd services/console
          npm ci
      - name: Lint frontend
        run: |
          cd services/console
          npm run lint
      - name: Test frontend
        run: |
          cd services/console
          npm test

      - name: Lint Markdown files
        run: npx markdownlint-cli "docs/agent-context/*.mdx"

      - name: Test handoff.py
        run: pytest agents/scripts/handoff.py

      - name: Validate context-pack schema
        run: python -c "import json, jsonschema; jsonschema.Draft7Validator.check_schema(json.load(open('docs/schemas/context-pack.json')))"

      - name: Security scan
        uses: aquasecurity/trivy-action@master
        with:
          scan-type: 'fs'
          format: 'sarif'
          output: 'trivy-results.sarif'
          scan-ref: '.'
      - name: Upload security scan results
        uses: github/codeql-action/upload-sarif@v3
        with:
          sarif_file: 'trivy-results.sarif'

# Create test_json_lint.py
cat > tests/ci/test_json_lint.py << 'EOF'
import json
from unittest.mock import mock_open, patch, Mock
from jsonschema import validate, ValidationError
import glob
import sys

def test_json_lint_success(mocker):
    mock_open_val = mock_open(read_data='{"valid": "json"}')
    mocker.patch('builtins.open', mock_open_val)
    mocker.patch('glob.glob', return_value=['docs/schemas/valid.json'])
    
    # Mock the validation to succeed
    mock_validate = Mock()
    mocker.patch('jsonschema.validate', mock_validate)
    
    # Call the validation logic
    schema_path = 'docs/schemas/handoff-card.schema.json'
    with open(schema_path) as f:
        schema = json.load(f)
    
    json_files = glob.glob('docs/schemas/*.json') + glob.glob('agents/scripts/*.json')
    
    for file in json_files:
        try:
            with open(file) as f:
                data = json.load(f)
            validate(instance=data, schema=schema)
            print(f'Validated {file}')
        except (ValidationError, json.JSONDecodeError) as e:
            print(f'Validation failed for {file}: {e}')
            sys.exit(1)
    
    mock_validate.assert_called_once()

def test_json_lint_failure(mocker):
    mock_open_val = mock_open(read_data='{"invalid": "json"}')  # Invalid JSON
    mocker.patch('builtins.open', side_effect=[
        Mock(read_data='{"valid": "json"}'),  # First file valid
        Mock(read_data='{"invalid": "json"}')  # Second file invalid
    ])
    mocker.patch('glob.glob', return_value=['docs/schemas/invalid.json'])
    
    # Mock the validation to raise ValidationError for the second file
    mock_validate = Mock()
    mock_validate.side_effect = [None, ValidationError("Validation error")]
    mocker.patch('jsonschema.validate', mock_validate)
    
    # Call the validation logic
    schema_path = 'docs/schemas/handoff-card.schema.json'
    with open(schema_path) as f:
        schema = json.load(f)
    
    # Capture stdout and stderr
    import io
    import sys
    old_stdout = sys.stdout
    old_stderr = sys.stderr
    sys.stdout = fake_out = io.StringIO()
    sys.stderr = fake_err = io.StringIO()
    
    try:
        with open('docs/schemas/invalid.json') as f:
            data = json.load(f)
        validate(instance=data, schema=schema)
        print(f'Validated docs/schemas/invalid.json')
    except (ValidationError, json.JSONDecodeError) as e:
        print(f'Validation failed for docs/schemas/invalid.json: {e}')
        sys.exit(1)
    
    sys.stdout = old_stdout
    sys.stderr = old_stderr
    
    output = fake_out.getvalue()
    error = fake_err.getvalue()
    
    assert 'Validation failed' in error
    assert 'sys.exit(1)' not in output  # It should exit with code 1, but in test we check the error
EOF

# Create test_diff_size.py
cat > tests/ci/test_diff_size.py << 'EOF'
import subprocess
import pytest
from unittest.mock import patch, Mock

def test_diff_size_under_limit(mocker):
    mock_run = Mock(return_code=0)
    mock_run.stdout = '1\t2\n3\t4\n'
    mocker.patch('subprocess.run', return_value=mock_run)
    
    # Mock awk to return total_lines = 10
    # This is a simplified test, in real we'd mock the entire command
    total_lines = 10
    if total_lines > 200:
        pytest.fail("Error: PR diff exceeds 200 lines limit")
    else:
        assert True, "Diff size check passed"

def test_diff_size_over_limit(mocker):
    mock_run = Mock(return_code=0)
    mock_run.stdout = '100\t200\n300\t400\n'  # Total lines > 200
    mocker.patch('subprocess.run', return_value=mock_run)
    
    with pytest.raises(AssertionError):
        # This should fail
        total_lines = 700
        if total_lines > 200:
            raise AssertionError("Error: PR diff exceeds 200 lines limit")
EOF

# Create test_plan_sync.py
cat > tests/ci/test_plan_sync.py << 'EOF'
import subprocess
import pytest
from unittest.mock import patch, Mock

def test_plan_sync_no_code_changes(mocker):
    mock_run = Mock(return_code=0)
    mock_run.stdout = ''  # No code changes
    mocker.patch('subprocess.run', return_value=mock_run)
    
    code_changes = 0
    plan_changes = 0
    if code_changes > 0 and plan_changes == 0:
        pytest.fail("Error: Code changes detected without corresponding plan file updates")
    else:
        assert True, "Plan sync check passed"

def test_plan_sync_with_plan_changes(mocker):
    mock_run = Mock(return_code=0)
    mock_run.stdout = '1\n'  # Code changes, but plan changes also
    mocker.patch('subprocess.run', return_value=mock_run)
    
    code_changes = 1
    plan_changes = 1
    if code_changes > 0 and plan_changes == 0:
        pytest.fail("Error: Code changes detected without corresponding plan file updates")
    else:
        assert True, "Plan sync check passed"

def test_plan_sync_with_code_changes_no_plan(mocker):
    mock_run = Mock(return_code=0)
    mock_run.stdout = '1\n'  # Code changes, no plan changes
    mocker.patch('subprocess.run', return_value=mock_run)
    
    code_changes = 1
    plan_changes = 0
    with pytest.raises(AssertionError):
        if code_changes > 0 and plan_changes == 0:
            raise AssertionError("Error: Code changes detected without corresponding plan file updates")
EOF
